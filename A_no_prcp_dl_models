{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1BPeKjegcSGlCSYNEJnBzuZepY9Fh4RuS","authorship_tag":"ABX9TyMLDoKJ9l0WY2xrlFGUGECi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["RNN"],"metadata":{"id":"j34KV65Wl7VG"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, Dense\n","from sklearn.metrics import mean_absolute_error\n","\n","# Load and preprocess data\n","data = pd.read_csv('/content/drive/MyDrive/AI ML IITM saasthra/A_noPRCP.csv', parse_dates=['DATE'], index_col='DATE')\n","test_data = pd.read_csv('/content/drive/MyDrive/AI ML IITM saasthra/A_noPRCP_test.csv', parse_dates=['DATE'], index_col='DATE')\n","\n","# Normalize data\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","train_scaled = scaler.fit_transform(data[['Tavg_A']])\n","test_scaled = scaler.transform(test_data[['Tavg_A']])\n","\n","# Convert to time series format\n","def create_dataset(dataset, look_back=1):\n","    X, Y = [], []\n","    for i in range(len(dataset) - look_back):\n","        X.append(dataset[i:(i + look_back), 0])\n","        Y.append(dataset[i + look_back, 0])\n","    return np.array(X), np.array(Y)\n","\n","look_back = 3\n","X_train, y_train = create_dataset(train_scaled, look_back)\n","X_test, y_test = create_dataset(test_scaled, look_back)\n","\n","X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","# Build the RNN model\n","model = Sequential()\n","model.add(SimpleRNN(50, input_shape=(look_back, 1)))\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mean_absolute_error')\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=50, batch_size=1, verbose=2)\n","\n","# Make predictions\n","predictions = model.predict(X_test)\n","predictions = scaler.inverse_transform(predictions)\n","\n","# Evaluate\n","mae = mean_absolute_error(test_data['Tavg_A'][look_back:], predictions)\n","print(f'Mean Absolute Error: {mae}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqvCAYF5ljq6","executionInfo":{"status":"ok","timestamp":1725295012171,"user_tz":-330,"elapsed":109768,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"9c36f1bb-df8b-4639-82e9-c102d387c02f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["809/809 - 3s - 3ms/step - loss: 0.0849\n","Epoch 2/50\n","809/809 - 1s - 2ms/step - loss: 0.0738\n","Epoch 3/50\n","809/809 - 3s - 4ms/step - loss: 0.0738\n","Epoch 4/50\n","809/809 - 3s - 4ms/step - loss: 0.0727\n","Epoch 5/50\n","809/809 - 3s - 4ms/step - loss: 0.0727\n","Epoch 6/50\n","809/809 - 4s - 5ms/step - loss: 0.0742\n","Epoch 7/50\n","809/809 - 2s - 2ms/step - loss: 0.0730\n","Epoch 8/50\n","809/809 - 3s - 3ms/step - loss: 0.0722\n","Epoch 9/50\n","809/809 - 2s - 2ms/step - loss: 0.0707\n","Epoch 10/50\n","809/809 - 2s - 3ms/step - loss: 0.0710\n","Epoch 11/50\n","809/809 - 3s - 4ms/step - loss: 0.0726\n","Epoch 12/50\n","809/809 - 4s - 4ms/step - loss: 0.0723\n","Epoch 13/50\n","809/809 - 3s - 3ms/step - loss: 0.0711\n","Epoch 14/50\n","809/809 - 3s - 3ms/step - loss: 0.0715\n","Epoch 15/50\n","809/809 - 1s - 2ms/step - loss: 0.0701\n","Epoch 16/50\n","809/809 - 5s - 7ms/step - loss: 0.0704\n","Epoch 17/50\n","809/809 - 2s - 3ms/step - loss: 0.0705\n","Epoch 18/50\n","809/809 - 3s - 4ms/step - loss: 0.0697\n","Epoch 19/50\n","809/809 - 2s - 3ms/step - loss: 0.0703\n","Epoch 20/50\n","809/809 - 2s - 3ms/step - loss: 0.0701\n","Epoch 21/50\n","809/809 - 4s - 5ms/step - loss: 0.0705\n","Epoch 22/50\n","809/809 - 3s - 4ms/step - loss: 0.0708\n","Epoch 23/50\n","809/809 - 1s - 1ms/step - loss: 0.0693\n","Epoch 24/50\n","809/809 - 1s - 2ms/step - loss: 0.0703\n","Epoch 25/50\n","809/809 - 1s - 2ms/step - loss: 0.0706\n","Epoch 26/50\n","809/809 - 1s - 2ms/step - loss: 0.0701\n","Epoch 27/50\n","809/809 - 1s - 2ms/step - loss: 0.0698\n","Epoch 28/50\n","809/809 - 2s - 2ms/step - loss: 0.0700\n","Epoch 29/50\n","809/809 - 2s - 3ms/step - loss: 0.0697\n","Epoch 30/50\n","809/809 - 2s - 2ms/step - loss: 0.0696\n","Epoch 31/50\n","809/809 - 2s - 3ms/step - loss: 0.0701\n","Epoch 32/50\n","809/809 - 1s - 2ms/step - loss: 0.0693\n","Epoch 33/50\n","809/809 - 1s - 2ms/step - loss: 0.0694\n","Epoch 34/50\n","809/809 - 1s - 2ms/step - loss: 0.0690\n","Epoch 35/50\n","809/809 - 1s - 2ms/step - loss: 0.0684\n","Epoch 36/50\n","809/809 - 3s - 4ms/step - loss: 0.0695\n","Epoch 37/50\n","809/809 - 2s - 2ms/step - loss: 0.0692\n","Epoch 38/50\n","809/809 - 2s - 2ms/step - loss: 0.0687\n","Epoch 39/50\n","809/809 - 2s - 3ms/step - loss: 0.0688\n","Epoch 40/50\n","809/809 - 1s - 2ms/step - loss: 0.0693\n","Epoch 41/50\n","809/809 - 1s - 2ms/step - loss: 0.0692\n","Epoch 42/50\n","809/809 - 1s - 2ms/step - loss: 0.0691\n","Epoch 43/50\n","809/809 - 2s - 3ms/step - loss: 0.0685\n","Epoch 44/50\n","809/809 - 2s - 2ms/step - loss: 0.0683\n","Epoch 45/50\n","809/809 - 3s - 3ms/step - loss: 0.0689\n","Epoch 46/50\n","809/809 - 2s - 2ms/step - loss: 0.0687\n","Epoch 47/50\n","809/809 - 1s - 2ms/step - loss: 0.0684\n","Epoch 48/50\n","809/809 - 2s - 3ms/step - loss: 0.0677\n","Epoch 49/50\n","809/809 - 1s - 2ms/step - loss: 0.0682\n","Epoch 50/50\n","809/809 - 1s - 1ms/step - loss: 0.0690\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Mean Absolute Error: 5.122056477084755\n"]}]},{"cell_type":"markdown","source":["1D CNN"],"metadata":{"id":"OCzGvud_l2qN"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","from sklearn.metrics import mean_absolute_error\n","\n","# Load and preprocess data\n","data = pd.read_csv('/content/drive/MyDrive/AI ML IITM saasthra/A_noPRCP.csv', parse_dates=['DATE'], index_col='DATE')\n","test_data = pd.read_csv('/content/drive/MyDrive/AI ML IITM saasthra/A_noPRCP_test.csv', parse_dates=['DATE'], index_col='DATE')\n","\n","# Normalize data\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","train_scaled = scaler.fit_transform(data[['Tavg_A']])\n","test_scaled = scaler.transform(test_data[['Tavg_A']])\n","\n","# Convert to time series format\n","def create_dataset(dataset, look_back=1):\n","    X, Y = [], []\n","    for i in range(len(dataset) - look_back):\n","        X.append(dataset[i:(i + look_back), 0])\n","        Y.append(dataset[i + look_back, 0])\n","    return np.array(X), np.array(Y)\n","\n","look_back = 3\n","X_train, y_train = create_dataset(train_scaled, look_back)\n","X_test, y_test = create_dataset(test_scaled, look_back)\n","\n","X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","# Build the 1D CNN model\n","model = Sequential()\n","model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(look_back, 1)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mean_absolute_error')\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=50, batch_size=1, verbose=2)\n","\n","# Make predictions\n","predictions = model.predict(X_test)\n","predictions = scaler.inverse_transform(predictions)\n","\n","# Evaluate\n","mae = mean_absolute_error(test_data['Tavg_A'][look_back:], predictions)\n","print(f'Mean Absolute Error: {mae}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPYMgxvIly9x","executionInfo":{"status":"ok","timestamp":1725295310521,"user_tz":-330,"elapsed":75755,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"ec12563e-c891-4f28-dfac-8a5ce8fe581f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["809/809 - 2s - 3ms/step - loss: 0.0813\n","Epoch 2/50\n","809/809 - 1s - 2ms/step - loss: 0.0743\n","Epoch 3/50\n","809/809 - 1s - 2ms/step - loss: 0.0725\n","Epoch 4/50\n","809/809 - 1s - 1ms/step - loss: 0.0707\n","Epoch 5/50\n","809/809 - 1s - 1ms/step - loss: 0.0700\n","Epoch 6/50\n","809/809 - 1s - 1ms/step - loss: 0.0704\n","Epoch 7/50\n","809/809 - 1s - 1ms/step - loss: 0.0709\n","Epoch 8/50\n","809/809 - 2s - 2ms/step - loss: 0.0695\n","Epoch 9/50\n","809/809 - 3s - 4ms/step - loss: 0.0677\n","Epoch 10/50\n","809/809 - 2s - 2ms/step - loss: 0.0699\n","Epoch 11/50\n","809/809 - 1s - 2ms/step - loss: 0.0684\n","Epoch 12/50\n","809/809 - 1s - 1ms/step - loss: 0.0681\n","Epoch 13/50\n","809/809 - 1s - 2ms/step - loss: 0.0685\n","Epoch 14/50\n","809/809 - 1s - 2ms/step - loss: 0.0671\n","Epoch 15/50\n","809/809 - 1s - 2ms/step - loss: 0.0669\n","Epoch 16/50\n","809/809 - 1s - 1ms/step - loss: 0.0667\n","Epoch 17/50\n","809/809 - 2s - 2ms/step - loss: 0.0672\n","Epoch 18/50\n","809/809 - 2s - 2ms/step - loss: 0.0663\n","Epoch 19/50\n","809/809 - 2s - 3ms/step - loss: 0.0654\n","Epoch 20/50\n","809/809 - 2s - 2ms/step - loss: 0.0651\n","Epoch 21/50\n","809/809 - 1s - 2ms/step - loss: 0.0651\n","Epoch 22/50\n","809/809 - 1s - 2ms/step - loss: 0.0667\n","Epoch 23/50\n","809/809 - 1s - 1ms/step - loss: 0.0656\n","Epoch 24/50\n","809/809 - 1s - 2ms/step - loss: 0.0658\n","Epoch 25/50\n","809/809 - 1s - 1ms/step - loss: 0.0644\n","Epoch 26/50\n","809/809 - 1s - 2ms/step - loss: 0.0636\n","Epoch 27/50\n","809/809 - 2s - 2ms/step - loss: 0.0646\n","Epoch 28/50\n","809/809 - 2s - 3ms/step - loss: 0.0652\n","Epoch 29/50\n","809/809 - 2s - 2ms/step - loss: 0.0642\n","Epoch 30/50\n","809/809 - 2s - 2ms/step - loss: 0.0648\n","Epoch 31/50\n","809/809 - 1s - 2ms/step - loss: 0.0650\n","Epoch 32/50\n","809/809 - 1s - 2ms/step - loss: 0.0640\n","Epoch 33/50\n","809/809 - 1s - 1ms/step - loss: 0.0644\n","Epoch 34/50\n","809/809 - 1s - 1ms/step - loss: 0.0644\n","Epoch 35/50\n","809/809 - 1s - 2ms/step - loss: 0.0641\n","Epoch 36/50\n","809/809 - 1s - 1ms/step - loss: 0.0638\n","Epoch 37/50\n","809/809 - 2s - 2ms/step - loss: 0.0640\n","Epoch 38/50\n","809/809 - 3s - 3ms/step - loss: 0.0633\n","Epoch 39/50\n","809/809 - 2s - 2ms/step - loss: 0.0634\n","Epoch 40/50\n","809/809 - 1s - 2ms/step - loss: 0.0633\n","Epoch 41/50\n","809/809 - 1s - 1ms/step - loss: 0.0638\n","Epoch 42/50\n","809/809 - 1s - 2ms/step - loss: 0.0633\n","Epoch 43/50\n","809/809 - 1s - 2ms/step - loss: 0.0634\n","Epoch 44/50\n","809/809 - 1s - 2ms/step - loss: 0.0637\n","Epoch 45/50\n","809/809 - 1s - 2ms/step - loss: 0.0632\n","Epoch 46/50\n","809/809 - 1s - 2ms/step - loss: 0.0631\n","Epoch 47/50\n","809/809 - 2s - 2ms/step - loss: 0.0642\n","Epoch 48/50\n","809/809 - 2s - 3ms/step - loss: 0.0632\n","Epoch 49/50\n","809/809 - 2s - 3ms/step - loss: 0.0634\n","Epoch 50/50\n","809/809 - 1s - 2ms/step - loss: 0.0629\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e169694cee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n","Mean Absolute Error: 6.468955817486858\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from sklearn.metrics import mean_absolute_error\n","\n","# Load and preprocess data\n","data = pd.read_csv('/content/drive/MyDrive/AI ML IITM saasthra/A_noPRCP.csv', parse_dates=['DATE'], index_col='DATE')\n","test_data = pd.read_csv('/content/drive/MyDrive/AI ML IITM saasthra/A_noPRCP_test.csv', parse_dates=['DATE'], index_col='DATE')\n","\n","# Normalize data\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","train_scaled = scaler.fit_transform(data[['Tavg_A']])\n","test_scaled = scaler.transform(test_data[['Tavg_A']])\n","\n","# Convert to time series format\n","def create_dataset(dataset, look_back=1):\n","    X, Y = [], []\n","    for i in range(len(dataset) - look_back):\n","        X.append(dataset[i:(i + look_back), 0])\n","        Y.append(dataset[i + look_back, 0])\n","    return np.array(X), np.array(Y)\n","\n","look_back = 10  # Increased look_back period\n","X_train, y_train = create_dataset(train_scaled, look_back)\n","X_test, y_test = create_dataset(test_scaled, look_back)\n","\n","X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","# Build the LSTM model (more complex than SimpleRNN)\n","model = Sequential()\n","model.add(LSTM(100, return_sequences=True, input_shape=(look_back, 1)))  # Increased units\n","model.add(Dropout(0.2))  # Dropout to prevent overfitting\n","model.add(LSTM(50))  # Another LSTM layer\n","model.add(Dropout(0.2))\n","model.add(Dense(1))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_absolute_error')\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=2)  # Increased epochs and batch_size\n","\n","# Make predictions\n","predictions = model.predict(X_test)\n","predictions = scaler.inverse_transform(predictions)\n","\n","# Evaluate\n","mae = mean_absolute_error(test_data['Tavg_A'][look_back:], predictions)\n","print(f'Mean Absolute Error: {mae}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"He1Ev69ElzaO","executionInfo":{"status":"ok","timestamp":1725295451983,"user_tz":-330,"elapsed":79428,"user":{"displayName":"JANE","userId":"04368026904399864163"}},"outputId":"f4c5ca44-215d-464b-914f-59e88d317623"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["51/51 - 4s - 74ms/step - loss: 0.1145\n","Epoch 2/100\n","51/51 - 1s - 12ms/step - loss: 0.0828\n","Epoch 3/100\n","51/51 - 1s - 13ms/step - loss: 0.0797\n","Epoch 4/100\n","51/51 - 1s - 14ms/step - loss: 0.0800\n","Epoch 5/100\n","51/51 - 1s - 11ms/step - loss: 0.0803\n","Epoch 6/100\n","51/51 - 1s - 11ms/step - loss: 0.0772\n","Epoch 7/100\n","51/51 - 1s - 11ms/step - loss: 0.0765\n","Epoch 8/100\n","51/51 - 1s - 18ms/step - loss: 0.0776\n","Epoch 9/100\n","51/51 - 1s - 26ms/step - loss: 0.0757\n","Epoch 10/100\n","51/51 - 1s - 24ms/step - loss: 0.0752\n","Epoch 11/100\n","51/51 - 2s - 33ms/step - loss: 0.0768\n","Epoch 12/100\n","51/51 - 1s - 23ms/step - loss: 0.0801\n","Epoch 13/100\n","51/51 - 1s - 22ms/step - loss: 0.0796\n","Epoch 14/100\n","51/51 - 1s - 16ms/step - loss: 0.0738\n","Epoch 15/100\n","51/51 - 1s - 11ms/step - loss: 0.0763\n","Epoch 16/100\n","51/51 - 1s - 12ms/step - loss: 0.0724\n","Epoch 17/100\n","51/51 - 1s - 11ms/step - loss: 0.0711\n","Epoch 18/100\n","51/51 - 1s - 11ms/step - loss: 0.0732\n","Epoch 19/100\n","51/51 - 1s - 11ms/step - loss: 0.0728\n","Epoch 20/100\n","51/51 - 1s - 11ms/step - loss: 0.0716\n","Epoch 21/100\n","51/51 - 1s - 11ms/step - loss: 0.0726\n","Epoch 22/100\n","51/51 - 1s - 11ms/step - loss: 0.0743\n","Epoch 23/100\n","51/51 - 1s - 11ms/step - loss: 0.0736\n","Epoch 24/100\n","51/51 - 1s - 12ms/step - loss: 0.0711\n","Epoch 25/100\n","51/51 - 1s - 16ms/step - loss: 0.0726\n","Epoch 26/100\n","51/51 - 1s - 26ms/step - loss: 0.0734\n","Epoch 27/100\n","51/51 - 1s - 25ms/step - loss: 0.0727\n","Epoch 28/100\n","51/51 - 1s - 20ms/step - loss: 0.0719\n","Epoch 29/100\n","51/51 - 1s - 23ms/step - loss: 0.0708\n","Epoch 30/100\n","51/51 - 1s - 12ms/step - loss: 0.0718\n","Epoch 31/100\n","51/51 - 1s - 11ms/step - loss: 0.0729\n","Epoch 32/100\n","51/51 - 1s - 13ms/step - loss: 0.0702\n","Epoch 33/100\n","51/51 - 1s - 11ms/step - loss: 0.0718\n","Epoch 34/100\n","51/51 - 1s - 11ms/step - loss: 0.0710\n","Epoch 35/100\n","51/51 - 1s - 13ms/step - loss: 0.0698\n","Epoch 36/100\n","51/51 - 1s - 11ms/step - loss: 0.0714\n","Epoch 37/100\n","51/51 - 1s - 11ms/step - loss: 0.0704\n","Epoch 38/100\n","51/51 - 1s - 13ms/step - loss: 0.0711\n","Epoch 39/100\n","51/51 - 1s - 11ms/step - loss: 0.0706\n","Epoch 40/100\n","51/51 - 1s - 11ms/step - loss: 0.0710\n","Epoch 41/100\n","51/51 - 1s - 12ms/step - loss: 0.0696\n","Epoch 42/100\n","51/51 - 1s - 12ms/step - loss: 0.0712\n","Epoch 43/100\n","51/51 - 1s - 11ms/step - loss: 0.0689\n","Epoch 44/100\n","51/51 - 1s - 17ms/step - loss: 0.0708\n","Epoch 45/100\n","51/51 - 1s - 27ms/step - loss: 0.0676\n","Epoch 46/100\n","51/51 - 1s - 25ms/step - loss: 0.0706\n","Epoch 47/100\n","51/51 - 1s - 18ms/step - loss: 0.0692\n","Epoch 48/100\n","51/51 - 1s - 16ms/step - loss: 0.0688\n","Epoch 49/100\n","51/51 - 1s - 12ms/step - loss: 0.0696\n","Epoch 50/100\n","51/51 - 1s - 11ms/step - loss: 0.0696\n","Epoch 51/100\n","51/51 - 1s - 11ms/step - loss: 0.0687\n","Epoch 52/100\n","51/51 - 1s - 11ms/step - loss: 0.0693\n","Epoch 53/100\n","51/51 - 1s - 13ms/step - loss: 0.0689\n","Epoch 54/100\n","51/51 - 1s - 12ms/step - loss: 0.0684\n","Epoch 55/100\n","51/51 - 1s - 12ms/step - loss: 0.0706\n","Epoch 56/100\n","51/51 - 1s - 13ms/step - loss: 0.0692\n","Epoch 57/100\n","51/51 - 1s - 11ms/step - loss: 0.0691\n","Epoch 58/100\n","51/51 - 1s - 13ms/step - loss: 0.0724\n","Epoch 59/100\n","51/51 - 1s - 13ms/step - loss: 0.0690\n","Epoch 60/100\n","51/51 - 1s - 12ms/step - loss: 0.0671\n","Epoch 61/100\n","51/51 - 1s - 13ms/step - loss: 0.0690\n","Epoch 62/100\n","51/51 - 1s - 12ms/step - loss: 0.0690\n","Epoch 63/100\n","51/51 - 1s - 13ms/step - loss: 0.0684\n","Epoch 64/100\n","51/51 - 1s - 14ms/step - loss: 0.0685\n","Epoch 65/100\n","51/51 - 1s - 29ms/step - loss: 0.0684\n","Epoch 66/100\n","51/51 - 1s - 18ms/step - loss: 0.0676\n","Epoch 67/100\n","51/51 - 1s - 25ms/step - loss: 0.0690\n","Epoch 68/100\n","51/51 - 1s - 16ms/step - loss: 0.0665\n","Epoch 69/100\n","51/51 - 1s - 11ms/step - loss: 0.0672\n","Epoch 70/100\n","51/51 - 1s - 11ms/step - loss: 0.0711\n","Epoch 71/100\n","51/51 - 1s - 12ms/step - loss: 0.0686\n","Epoch 72/100\n","51/51 - 1s - 12ms/step - loss: 0.0675\n","Epoch 73/100\n","51/51 - 1s - 13ms/step - loss: 0.0683\n","Epoch 74/100\n","51/51 - 1s - 12ms/step - loss: 0.0692\n","Epoch 75/100\n","51/51 - 1s - 11ms/step - loss: 0.0673\n","Epoch 76/100\n","51/51 - 1s - 12ms/step - loss: 0.0682\n","Epoch 77/100\n","51/51 - 1s - 14ms/step - loss: 0.0677\n","Epoch 78/100\n","51/51 - 1s - 23ms/step - loss: 0.0681\n","Epoch 79/100\n","51/51 - 1s - 13ms/step - loss: 0.0679\n","Epoch 80/100\n","51/51 - 1s - 13ms/step - loss: 0.0679\n","Epoch 81/100\n","51/51 - 1s - 24ms/step - loss: 0.0680\n","Epoch 82/100\n","51/51 - 1s - 13ms/step - loss: 0.0675\n","Epoch 83/100\n","51/51 - 2s - 30ms/step - loss: 0.0670\n","Epoch 84/100\n","51/51 - 1s - 25ms/step - loss: 0.0674\n","Epoch 85/100\n","51/51 - 1s - 18ms/step - loss: 0.0692\n","Epoch 86/100\n","51/51 - 1s - 18ms/step - loss: 0.0669\n","Epoch 87/100\n","51/51 - 1s - 12ms/step - loss: 0.0690\n","Epoch 88/100\n","51/51 - 1s - 11ms/step - loss: 0.0678\n","Epoch 89/100\n","51/51 - 1s - 11ms/step - loss: 0.0665\n","Epoch 90/100\n","51/51 - 1s - 11ms/step - loss: 0.0671\n","Epoch 91/100\n","51/51 - 1s - 13ms/step - loss: 0.0663\n","Epoch 92/100\n","51/51 - 1s - 12ms/step - loss: 0.0679\n","Epoch 93/100\n","51/51 - 1s - 11ms/step - loss: 0.0684\n","Epoch 94/100\n","51/51 - 1s - 13ms/step - loss: 0.0675\n","Epoch 95/100\n","51/51 - 1s - 12ms/step - loss: 0.0672\n","Epoch 96/100\n","51/51 - 1s - 13ms/step - loss: 0.0676\n","Epoch 97/100\n","51/51 - 1s - 13ms/step - loss: 0.0668\n","Epoch 98/100\n","51/51 - 1s - 11ms/step - loss: 0.0663\n","Epoch 99/100\n","51/51 - 1s - 12ms/step - loss: 0.0670\n","Epoch 100/100\n","51/51 - 1s - 12ms/step - loss: 0.0656\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e169631d240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n","Mean Absolute Error: 5.9157349310448595\n"]}]}]}